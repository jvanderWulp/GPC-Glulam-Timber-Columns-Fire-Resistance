{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654a13b7-a5ff-4b15-9a00-7d35557de51c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from scipy.stats import qmc\n",
    "\n",
    "import GPy\n",
    "import torch\n",
    "\n",
    "from ModelSetting_new import Model\n",
    "from UtilityFunctions import U_SMOCU\n",
    "from OptimizeMethod import Multi_start_SGD\n",
    "\n",
    "from safir_runner import SafirRunner\n",
    "from al_plotting import plot_acquisition_values, plot_relative_acq_change, plot_log_likelihood, plot_misclassification, plot_gp_decision_boundary_2d, plot_gp_decision_boundary_3d, plot_flips_frac_values, plot_boundary_spread\n",
    "from al_helpers import DesignVar, normalise_point, denormalise_point, df_to_training_data, save_model_state, load_model_state, relative_sequential_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cae760-9099-47f7-8e55-e1c2988adae3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "design_vars = [\n",
    "    DesignVar(\"t_h\", 1.0, 60.0, \"min\"),   # heating duration\n",
    "    DesignVar(\"B\",   0.250, 0.500, \"m\"),  # column width\n",
    "    DesignVar(\"F\", 300000, 1800000, \"N\"),  # Applied force\n",
    "    DesignVar(\"l\", 3.00, 5.00, \"m\"),       # column length\n",
    "    DesignVar(\"T_max\", 600, 1200, \"°C\"),   # Maximum temperature \n",
    "    DesignVar(\"r_cool\", 6, 12, \"°C/min\"),  # cooling rate\n",
    "    # DesignVar(\"rho\", 360, 490,\"kg/m^3\"),  # Density\n",
    "    # DesignVar(\"E\", 9.44e9, 17.37e9, \"N/m^2\"),   # Modulus of Elasticity\n",
    "    # DesignVar(\"f_c\", 35.7e6, 45.8e6,\"N/m^2\"),    # Compressive strength\n",
    "    # DesignVar(\"e0\", 0.013275, 0.026865, \"m\"),    # Eccentricity\n",
    "]\n",
    "d = len(design_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104888f-2c23-4adf-be54-e90af898dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(r\"C:\\Users\\justu\\Documents\\Master_Thesis\\SAFIR\\Files\\Active_Learning\\TEST\")\n",
    "base_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_path   = base_path / \"Data_AL.csv\"\n",
    "kernel_path = base_path / \"Kernel_AL.json\"\n",
    "\n",
    "\n",
    "column_names = [\n",
    "    \"Analysis\", \"e0\", \"rho\", \"E\", \"mu\", \"f_c\", \"f_t\", \"w\", \"h_ch\", \"h_cc\", \"eps\",\n",
    "    \"B\", \"l\", \"F\", \"t_h\", \"T_max\", \"r_cool\", \"H\", \"t_end\", \"t_end_guess\",\n",
    "    \"fine_size\", \"n_elements\", \"failure\", \"failure_time\",\n",
    "    \"time_thermo\", \"time_mech\", \"time_tot\", \"stiffness\",\n",
    "]\n",
    "\n",
    "runner = SafirRunner(base_dir=base_path, column_names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949b476-650e-436a-b385-8f3a71d9d141",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bernoulli likelihood for classification\n",
    "lik = GPy.likelihoods.Bernoulli()\n",
    "\n",
    "# ARD RBF kernel with one lengthscale per input dimension\n",
    "kernel = GPy.kern.RBF(input_dim=d, variance=3.0, lengthscale=0.4, ARD=True)\n",
    "\n",
    "x_bounds = [0.0, 1.0]          # Surrogate model design space interval.\n",
    "\n",
    "xl = np.full(d, x_bounds[0])\n",
    "xu = np.full(d, x_bounds[1])\n",
    "xinterval = (xl, xu)\n",
    "\n",
    "# Uniform prior over the interval\n",
    "volume = np.prod(xu - xl)\n",
    "px = 1.0 / volume\n",
    "px_log = -np.log(volume)\n",
    "\n",
    "c_num = 2  # binary classification\n",
    "parameters = [d, c_num, kernel, lik]\n",
    "\n",
    "vinterval = None\n",
    "linterval = (0.1, 1.0)\n",
    "prior_mean = -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e5f7b6-3eaf-4519-9d1e-5eac04eeb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing data if present\n",
    "use_existing_data = False\n",
    "if data_path.exists():\n",
    "    df = pd.read_csv(data_path)\n",
    "    if len(df) > 0:\n",
    "        use_existing_data = True\n",
    "else:\n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "if use_existing_data:\n",
    "    print(f\"Warm start: using existing dataset with {len(df)} rows from {data_path}\")\n",
    "    X_init, Y_init = df_to_training_data(df, design_vars, y_col=\"failure\")\n",
    "\n",
    "    if kernel_path.exists():\n",
    "        print(f\"Found saved model state at {kernel_path}. Reloading.\")\n",
    "        kernel, saved_prior_mean = load_model_state(\n",
    "            kernel_path=kernel_path,\n",
    "            d=d,\n",
    "            expected_design_vars=[dv.name for dv in design_vars],\n",
    "            expected_xinterval=xinterval,\n",
    "        )\n",
    "        if saved_prior_mean is not None:\n",
    "            prior_mean = float(saved_prior_mean)\n",
    "\n",
    "    parameters = [d, c_num, kernel, lik]\n",
    "\n",
    "else:\n",
    "    print(\"Cold start: no existing data found. Running initial SAFIR simulation.\")\n",
    "    # Initial simulation point\n",
    "    phys0 = {\n",
    "        \"t_h\": 50.0,   # [min]\n",
    "        \"B\":   0.260,  # [m]\n",
    "        \"F\":   500000, # [N]\n",
    "        \"l\":    3.2,   # [m]\n",
    "        \"T_max\": 1150, # [°C]\n",
    "        \"r_cool\": 11.5, # [°C/min]\n",
    "        # \"rho\": 380, # [kg/m^3]\n",
    "        # \"E\": 10.0e9, # [N/m^2]\n",
    "        # \"f_c\": 38.0e6, # [N/m^2]\n",
    "        # \"e0\": 0.024, # [m]\n",
    "    }\n",
    "    y0, df = runner.run(phys0, df)\n",
    "    print(\"Initial failure label:\", y0)\n",
    "\n",
    "    X_init = normalise_point(phys0, design_vars)[None, :]\n",
    "    Y_init = np.array([[y0]], float)\n",
    "\n",
    "#  Build GPC model\n",
    "model = Model(\n",
    "    X=X_init,\n",
    "    Y=Y_init,\n",
    "    parameters=parameters,\n",
    "    xinterval=xinterval,\n",
    "    optimize=False,\n",
    "    kern_variance_fix=False,\n",
    "    kern_lengthscale_fix=False,\n",
    "    mean_fix=True,\n",
    "    vinterval=vinterval,\n",
    "    linterval=linterval,\n",
    "    prior_mean=prior_mean,\n",
    "    px_log=px_log,\n",
    ")\n",
    "\n",
    "print(\"Initial kernel:\", model.gpc.kern)\n",
    "print(\"Initial lengthscales:\", model.gpc.kern.lengthscale)\n",
    "print(\"Initial mean function:\", model.gpc.mean_function)\n",
    "print(\"Initial training points:\", model.gpc.X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a402a5db-9512-494d-b468-e97c93c9dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NR-SMOCU-SGD settings\n",
    "smocu_x_num   = 4000     # points to approximate SMOCU integral\n",
    "mc_search_num = 1_000_000     # candidates for intial Sobol search\n",
    "SGD_steps     = 200      # Amount of gradient steps\n",
    "mc_search_num_frac = 0.001   # Fraction of samples initial Sobol search which score best on closest to current decision boundary\n",
    "\n",
    "acq = U_SMOCU(\n",
    "    softtype=2,\n",
    "    k=20,\n",
    "    x_num=smocu_x_num,\n",
    "    approx_label=True   # NR-SMOCU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa12f47-e07d-4eaa-8eb2-5052296039db",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = base_path / \"AL_Log.csv\"\n",
    "AL_LOG_COLUMNS = [\n",
    "    \"global_iter\",\n",
    "    \"acq_value\",\n",
    "    \"miscl\",\n",
    "    \"log_likelihood\",\n",
    "    \"start_opt\",\n",
    "    \"count\",\n",
    "    \"optimisation_count\",\n",
    "    \"boundary_frac\", \n",
    "    \"flips_frac\",\n",
    "    \"flips_frac_count\",\n",
    "    \"plot_thresh\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522fbf7d-85af-4b30-8aec-174b7e1a6ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or initialise Active learning bookkeeping\n",
    "if log_path.exists():\n",
    "    al_log = pd.read_csv(log_path)\n",
    "    if len(al_log) > 0:\n",
    "        last_row = al_log.iloc[-1]\n",
    "        acq_list = al_log[\"acq_value\"].astype(float).tolist()\n",
    "        miscl_list = al_log[\"miscl\"].astype(float).tolist()\n",
    "        log_likelihood_list = al_log[\"log_likelihood\"].astype(float).tolist()\n",
    "        start_opt = bool(last_row[\"start_opt\"])\n",
    "        count = int(last_row[\"count\"])\n",
    "        optimisation_count = int(last_row[\"optimisation_count\"])\n",
    "        global_iter_start = int(last_row[\"global_iter\"])\n",
    "        boundary_frac_list = al_log[\"boundary_frac\"].astype(float).tolist()\n",
    "        flips_frac_list = al_log[\"flips_frac\"].astype(float).tolist()\n",
    "        flips_frac_count = int(last_row[\"flips_frac_count\"])\n",
    "        plot_thresh = float(last_row[\"plot_thresh\"])\n",
    "    else:\n",
    "        al_log = pd.DataFrame(columns=AL_LOG_COLUMNS)\n",
    "        acq_list = []\n",
    "        miscl_list = []\n",
    "        log_likelihood_list = []\n",
    "        start_opt = False\n",
    "        count = 0\n",
    "        optimisation_count = 0\n",
    "        global_iter_start = 0\n",
    "        boundary_frac_list = []\n",
    "        flips_frac_list = []\n",
    "        flips_frac_count = 0\n",
    "else:\n",
    "    al_log = pd.DataFrame(columns=AL_LOG_COLUMNS)\n",
    "    acq_list = []\n",
    "    miscl_list = []\n",
    "    log_likelihood_list = []\n",
    "    start_opt = False\n",
    "    count = 0\n",
    "    optimisation_count = 0\n",
    "    global_iter_start = 0\n",
    "    boundary_frac_list = []\n",
    "    flips_frac_list = []\n",
    "    flips_frac_count = 0\n",
    "\n",
    "print(\n",
    "    f\"AL resume state: global_iter_start={global_iter_start}, \"\n",
    "    f\"start_opt={start_opt}, count={count}, optimisation_count={optimisation_count}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d3f27-ab03-4f71-803a-6cb5dd3c10e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_existing_data and log_path.exists():\n",
    "    n_data = len(df)\n",
    "    n_log  = len(al_log)\n",
    "\n",
    "    if n_data == n_log + 1:\n",
    "        pass\n",
    "    elif n_data == n_log + 2:\n",
    "        print(f\"Warning: Detected one unlogged evaluation (Data rows {n_data}, AL log rows {n_log}).\")\n",
    "        print(\"Likely crash after SAFIR/data save but before AL_Log save.\")\n",
    "    else:\n",
    "        print(f\"Warning: Data rows ({n_data}) and AL log rows ({n_log}) are inconsistent.\")\n",
    "        print(\"Investigate: multiple missing log rows or mismatched base_path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934549b-77ac-4b1f-a4a6-cdb93a06c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monior set for Hyperparameter optimisation and convergence\n",
    "n_monitor = 1_000_000\n",
    "\n",
    "sampler = qmc.Sobol(d=d, scramble=True, seed=123)\n",
    "X_monitor = sampler.random(n_monitor)\n",
    "\n",
    "p_monitor = model.predict_proba(X_monitor)[:, 1]\n",
    "\n",
    "y_mon_now = (p_monitor >= 0.5).astype(int)\n",
    "y_mon_prev = y_mon_now.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d36bd-52b7-4323-9b9a-f6cb64d6996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimisation rule parameters\n",
    "opt_frac = 0.25       # Fraction of maximum change in boundary movement to start counting when to optimize hyperparameters\n",
    "opt_thresh = 20       # Count of boundary change under treshold for when to start optimizing hyperparameters\n",
    "opt_every = 10       # Do hyperparameter optimization every ... times\n",
    "\n",
    "# Convergence / stopping rule parameters (Convergence starts after the first try of kernel hyperparameter optimisation)\n",
    "boundary_frac_threshold = 0.01\n",
    "boundary_frac_threshold_2 = 0.05\n",
    "diff_boundary_frac_threshold = 0.0005\n",
    "miscl_window = 11\n",
    "miscl_thresh = 0.05\n",
    "diff_boundary_frac_window = 21\n",
    "converged = False\n",
    "\n",
    "n_iterations = 200    # Amount of iterations for active learning batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ae34f-5c0f-406e-957d-3893a444bb2a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_history = [X_init.copy()]\n",
    "Y_history = [Y_init.copy()]\n",
    "\n",
    "for it in range(n_iterations):\n",
    "    global_iter = global_iter_start + it + 1\n",
    "    print(f\"\\n=== Iteration {global_iter} ===\")\n",
    "    print(\"Mean function:\", model.gpc.mean_function)\n",
    "\n",
    "    # 1) Choose next query\n",
    "    x_star_norm, acq_value = Multi_start_SGD(\n",
    "        acq,\n",
    "        model=model,\n",
    "        mc_search_num=mc_search_num,\n",
    "        learning_rate=0.001,\n",
    "        n_starts=1,\n",
    "        top_frac=0.01,\n",
    "        n_sgd_steps=SGD_steps,\n",
    "        frac_mc_search=mc_search_num_frac,\n",
    "        return_field=False,\n",
    "    )\n",
    "\n",
    "    acq_list.append(acq_value)\n",
    "    acq_arr = np.array(acq_list)\n",
    "    acq_rel = relative_sequential_difference(acq_arr)\n",
    "\n",
    "    # 2) Map to physical space and run SAFIR\n",
    "    phys_star = denormalise_point(x_star_norm, design_vars)\n",
    "    print(\"Next physical point:\", phys_star)\n",
    "\n",
    "    y_star, df = runner.run(phys_star, df)\n",
    "\n",
    "    # 3) Update history\n",
    "    X_history.append(np.vstack([X_history[-1], x_star_norm]))\n",
    "    Y_history.append(np.vstack([Y_history[-1], [[y_star]]]))\n",
    "\n",
    "    lengthscales_before = np.asarray(model.gpc.kern.lengthscale).copy()\n",
    "\n",
    "    # 4) Decide whether to optimise hyperparameters\n",
    "    do_opt = False\n",
    "    if flips_frac_count > opt_thresh:\n",
    "        start_opt = True\n",
    "        if (count % opt_every == 0) and start_opt:\n",
    "            do_opt = True\n",
    "        if start_opt:\n",
    "            count += 1\n",
    "    \n",
    "    model.Update(\n",
    "        x_star_norm,\n",
    "        y_star,\n",
    "        optimize=do_opt,\n",
    "        kern_variance_fix=False,\n",
    "        mean_fix=True,\n",
    "        ll_tol=0.0,\n",
    "    )\n",
    "    \n",
    "    save_model_state(model, kernel_path=kernel_path, prior_mean=prior_mean, xinterval=xinterval, design_vars=design_vars)\n",
    "    \n",
    "    log_likelihood = float(model.gpc.log_likelihood())\n",
    "    log_likelihood_list.append(log_likelihood)\n",
    "\n",
    "    lengthscales_after = np.asarray(model.gpc.kern.lengthscale)\n",
    "    if np.any(lengthscales_before != lengthscales_after):\n",
    "        optimisation_count += 1\n",
    "\n",
    "    # 5) Monitor AL data\n",
    "    miscl = model.training_misclassification()\n",
    "    miscl_list.append(miscl)\n",
    "    miscl_arr = np.array(miscl_list)\n",
    "\n",
    "    p_monitor = model.predict_proba(X_monitor)[:, 1]\n",
    "    boundary_mask = (p_monitor > 0.3) & (p_monitor < 0.7)\n",
    "    boundary_frac = boundary_mask.mean()\n",
    "    \n",
    "    y_mon_now = (p_monitor >= 0.5).astype(int)   \n",
    "    \n",
    "    flips_frac = np.mean(y_mon_now != y_mon_prev)\n",
    "    y_mon_prev = y_mon_now.copy()\n",
    "\n",
    "    boundary_frac_list.append(boundary_frac)\n",
    "    flips_frac_list.append(flips_frac)\n",
    "\n",
    "    if flips_frac < opt_frac * np.max(flips_frac_list):\n",
    "        flips_frac_count += 1\n",
    "\n",
    "    diff_boundary_frac = np.diff(np.array(boundary_frac_list))\n",
    "\n",
    "    if count == 0:\n",
    "        plot_thresh = opt_frac * np.max(flips_frac_list)\n",
    "\n",
    "    print(\"Next normalised point:\", x_star_norm)\n",
    "    print(\"Label (failure?):\", y_star, \"   Acquisition:\", acq_value)\n",
    "    print(\"Kernel variance:\", model.gpc.kern.variance)\n",
    "    print(\"Kernel lengthscales:\", model.gpc.kern.lengthscale)\n",
    "    print(\"Log-likelihood:\", log_likelihood)\n",
    "    if len(acq_rel) > 10:\n",
    "        print(\"Relative acquisition values:\", acq_rel[-11:])\n",
    "    print(\"Count from moment of optimisation:\", count)\n",
    "    print(\"Misclassification metric:\", miscl)\n",
    "    print(\"Optimisation count:\", optimisation_count)\n",
    "    print(\"Flips_frac_count:\", flips_frac_count)\n",
    "    print(\"Boundary spread metric:\", boundary_frac)\n",
    "\n",
    "    \n",
    "    al_log.loc[len(al_log)] = {\n",
    "        \"global_iter\": int(global_iter),\n",
    "        \"acq_value\": float(acq_value),\n",
    "        \"miscl\": float(miscl),\n",
    "        \"log_likelihood\": float(log_likelihood),\n",
    "        \"start_opt\": bool(start_opt),\n",
    "        \"count\": int(count),\n",
    "        \"optimisation_count\": int(optimisation_count),\n",
    "        \"boundary_frac\": float(boundary_frac), \n",
    "        \"flips_frac\": float(flips_frac), \n",
    "        \"flips_frac_count\":  int(flips_frac_count),\n",
    "        \"plot_thresh\": float(plot_thresh)\n",
    "    }\n",
    "    \n",
    "    al_log.to_csv(log_path, index=False)\n",
    "\n",
    "    # Plotting of AL metrics\n",
    "    global_iterations = np.arange(1, len(acq_list)+1)\n",
    "    plot_flips_frac_values(global_iterations, np.array(flips_frac_list), plot_thresh, base_path / \"Figures\" / \"Boundary_change_vs_iterations.png\")\n",
    "    plot_boundary_spread(global_iterations, np.array(boundary_frac_list), boundary_frac_threshold, base_path / \"Figures\" / \"Boundary_spread_vs_iterations.png\")\n",
    "    plot_acquisition_values(global_iterations, acq_arr, base_path / \"Figures\" / \"Acquisition_vs_iterations.png\")\n",
    "    plot_relative_acq_change(global_iterations, acq_rel, base_path / \"Figures\" / \"RelAcqChange_vs_iterations.png\")\n",
    "    plot_log_likelihood(global_iterations, np.array(log_likelihood_list), base_path / \"Figures\" / \"LogLikelihood_vs_iterations.png\")\n",
    "    plot_misclassification(global_iterations, miscl_arr, base_path / \"Figures\" / \"Misclassification_vs_iterations.png\",\n",
    "                           miscl_threshold=miscl_thresh)\n",
    "\n",
    "    # Plotting of visualising 2D problem\n",
    "    if d == 2:\n",
    "        x_bounds = (design_vars[0].lower, design_vars[0].upper)\n",
    "        y_bounds = (design_vars[1].lower, design_vars[1].upper)\n",
    "    \n",
    "        plot_gp_decision_boundary_2d(\n",
    "            model=model,\n",
    "            X_norm=model.gpc.X,\n",
    "            y=model.gpc.Y.ravel().astype(int),\n",
    "            x_bounds=x_bounds,\n",
    "            y_bounds=y_bounds,\n",
    "            grid_res=150,\n",
    "            x_label=rf\"{design_vars[0].name} [{design_vars[0].unit}]\",\n",
    "            y_label=rf\"{design_vars[1].name} [{design_vars[1].unit}]\",\n",
    "            title=f\"GPC Decision Boundary – iteration {global_iter}\",\n",
    "            save_path= base_path / \"Figures\" / f\"GPC_Decision_Boundary_it_{global_iter}.png\",\n",
    "            show=False,\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # 6) Stopping rules\n",
    "    if count > 1 and boundary_frac_list[-1] < boundary_frac_threshold and np.all(miscl_arr[-miscl_window:] < miscl_thresh):\n",
    "        print(\n",
    "            f\"\\nStopping early at iteration {global_iter}: \"\n",
    "            f\"Boundary band < {boundary_frac_threshold}.\"\n",
    "        )\n",
    "        converged = True\n",
    "        break\n",
    "\n",
    "    # if count > 1 and boundary_frac_list[-1] < boundary_frac_threshold_2 and np.all(miscl_arr[-miscl_window:] < miscl_thresh) and np.all(diff_boundary_frac[-diff_boundary_frac_window:] < diff_boundary_frac_threshold):\n",
    "    #     print(\n",
    "    #         f\"\\nStopping early at iteration {global_iter}: \"\n",
    "    #         f\"Boundary band < {boundary_frac_threshold_2} and no improvement anymore on boundary spread metric.\"\n",
    "    #     )\n",
    "    #     converged = True\n",
    "    #     break\n",
    "\n",
    "X_final = X_history[-1]\n",
    "Y_final = Y_history[-1]\n",
    "print(\"\\nTotal evaluated points:\", X_final.shape[0])\n",
    "print(\"Final dataframe rows:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc3e351-a284-4456-b935-b98e3f58c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "if converged:\n",
    "    print(\"\\nConverged: training final optimised model on full dataset\")\n",
    "\n",
    "    X_current = np.asarray(model.gpc.X, float)\n",
    "    Y_current = np.asarray(model.gpc.Y, float).reshape(-1, 1)\n",
    "\n",
    "    final_model = model.ModelTrain(\n",
    "        X_current,\n",
    "        Y_current,\n",
    "        optimize=True,                \n",
    "        kern_lengthscale_fix=False,    \n",
    "        kern_variance_fix=False,      \n",
    "        mean_fix=True,                 \n",
    "    )\n",
    "\n",
    "    print(\"Final kernel:\")\n",
    "    print(\"Final variance:\", final_model.gpc.kern.variance)\n",
    "    print(\"Final lengthscales:\", final_model.gpc.kern.lengthscale)\n",
    "    print(\"Final log-likelihood:\", float(final_model.gpc.log_likelihood()))\n",
    "\n",
    "    final_model.gpc.save_model(str(base_path / \"Final_GPC\"), compress=True)\n",
    "    print(\n",
    "        'Final model is saved on base_path. '\n",
    "        'Model can be reloaded with: '\n",
    "        'gpc_loaded = GPy.core.GP.load_model(str(base_path / \"Final_GPC.zip\"))'\n",
    "    )\n",
    "\n",
    "    save_model_state(\n",
    "        final_model,\n",
    "        kernel_path=kernel_path,\n",
    "        prior_mean=prior_mean,\n",
    "        xinterval=xinterval,\n",
    "        design_vars=design_vars,\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nNot converged: skipping final hyperparameter optimisation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac898c10-58b4-4d79-ba56-b3202b2b6beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
